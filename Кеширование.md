 Закон Парето 20% данных создают 80% нагрузки
### Основные виды кеша

- Внутренний кеш - внутри программы. Минус в плохой горизонтальной масштабируемости. Так как пользователя прийдется удерживать в одном сервисе. Если сервис упал, то кеш пропадает. 
- Внешний кеш - находится на отдельном сервере. Легко масштабировать сервисы. Скорость работы медленная по сравнению в внутренним кешем.
- Многомерный кеш - это дерево всех кешей. Кеш браузера -> кеш прокси сервера -> внутренний кеш приложения -> внешний кеш приложения -> кэш движка базы данных.

### Оценка эффективности кеширования 

![[Эффективность Кеширования.png]]

### Стратегия Cache Aside

- Если запрос на запись, то можно не записывать данные в кеш, если нам важна скорость на запись. Можно записывать данные асинхронно, когда мы накопим сразу 50 запросов, то мы их запишем в кеш, это нужно для актуализации данных.

![[Read Aside.png]]![[Write Aside.png]]

### Стратегия Cache Through

- Сервис не знает про базу данных и работает только с кешем. Плюс в простой логике, но если кеш упадет, то наше приложение недоступно.

![[Cache Through.png]]

- Мы сначала идем в кеш, но сразу данные в кеш не записываем, сначала сохраняем их в базу, после получения ответа записываем данные в кеш и отдаем ответ сервису. Иногда это правило не соблюдается, если нам неважна актуальность данных.

![[Write Through.png]]

### Стратегия Cache Ahead

- Запросы никогда не попадают в базу данных напрямую. Приложение только читает данные из кеша, но не знает про базу данных. Запись в кеш осуществляет внешний модуль. Плюс в том, что мы не тратим время на кеширование данных, когда их читаем.

![[Cache Ahead.png]]

### Алгоритмы вытеснения данных

- Обычная очередь

![[FIFO.png]]

- Стек

![[LIFO.png]]

- #Used List recently used - вытесняется тот элемент, к которому дольше всего не было обращений. Прост в реализации, поэтому часто используется. В Redis есть из коробки.

![[LRU.png]]

- Most recently used - вытесняется тот элемент, который был последним использован

![[MRU.png]]

- #Used List frequently used - вытесняется элемент, к которому было меньше всего обращений

![[LFU.png]]

- Если нам заранее известно время, через которое нам понадобятся элементы, то мы вытесняем тот, который понадобится через наибольший промежуток времени. Нереализуем на практике на данный момент. Можно использовать программы, которые будут предсказывать время или квантовые компьютеры.

![[Алгоритм Белади.png]]

- #Used Улучшенная очередь. Если мы обращаемся к элементу, то ставим ему флаг used. Когда мы добавляем новый элемент, то мы идем по очереди и проверяем, если есть флаг used, то мы его обнуляем его и переносим элемент в конец очереди. Так идем, пока не найдем элемент, у которого не будет used флага, его и заменяем. Проблема в том, что если все флаги used, то алгоритм их перетрет и мы вернемся к обычной очереди.

![[Second Chance.png]]

- Улучшенная версия алгоритма second chance. Мы просто используем указатель, который ищет неиспользованный элемент и заменяет его на новый. Используется в linux для виртуальной памяти.

![[Clock.png]]

- У нас есть две обычные очереди и один лист, из которого вытесняется один дольше неиспользованный элемент. Если мы обратились к элементу 1FIFO, то ничего не происходит. Если мы обратились к элементу 2FIFO, то он переходит в LRU. Если мы вытеснили элемент из 1FIFO, то он переходит в 2FIFO. Если мы вытеснили элемент из 2FIFO, то он удаляется. Вторая очередь выступает зазором для данных, которые наврятли будут использованы, но если их использовали, то они перейдут в LRU.

![[2Q.png]]

- Segmented LRU - при повторном использовании элемента, он перемещается на уровень выше, при этом внутри каждой LRU все также удаляется наиболее долго неиспользованный элемент. То есть это LRU + LFU (удаляется элемент, к которому было меньше всего обращений), мы добавили немного частотности.

![[SLRU.png]]

- TLRU - мы добавляем к обычному LRU(вытесняет дольше всего неиспользованный) счетчик (TTL - time to live), по истечению которого элемент сам умирает.
- LRU-K - мы ведем отчет времени от второго, третеьего и т.д. использования элемента.

### Инвалидация данных

- Инвалидация по TTL(time to live) - сложность в подборе времени. Если слишком мало времени, то страдает Cache Hit. Если слишком много времени, то страдает актуализация.
- Если у нас одновременно и много данных становятся недействительными, то база данных может прилечь. Если все товары по акции, которые находятся в кеше до определенного момента(акция закончилась) умерли одновременно и пошли в базу данных обновляться, то это может положить базу. Чтобы этого избежать, нужно использовать `Jitter`, который будет добавлять время к TTL рандомно.
- `THUNDERING HERD PROBLEM` - если наш горячий ключ "Криштиану Роналду" ушел из кеша по TLL, огромное количество пользователей подают запрос на получение профиля, но его нет в кеше, тогда огромное количество запросов пойдет на базу данных, что может положить её. Для решения проблемы нужно лочить ключ кеша и ждать, когда данные подгрузятся из базы в кеш.
- Изменилась цена на товар, мы отправляем ключ события брокеру(kafka) и он уже инвалидирует(обновляет) данные в кеше.

![[Инвалидация по событию.png]]

- Версионирование кеша - добавление нового имени к элементу. То есть из базы данных подтягивается новый элемент с новым именем (v1, v2, ...)
- Если у нас две базы данных необходимо тегировать кеш, чтобы он обновлялся корректно. Тогда у нас будет обновляться только необходимый блок по индексу, а не весь кеш.

![[Тегирование кеша.png]]
